{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex optimization problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization problems\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & f_0(x)      &     \\\\\n",
    "\\text{subject to}\\; & f_i(x)\\leq 0& i=1,\\ldots,m \\\\\n",
    "& h_i(x) =   0& i=1,\\ldots,p\n",
    "\\label{eq:cvx_std_form}\n",
    "\\end{align}\n",
    "\n",
    "The set of points for which the objective and all constraint functions are \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{D} = \\bigcap_{i=0}^m \\mathbf{dom} f_i \\cap\n",
    "\\bigcap_{i=1}^p \\mathbf{dom}\\;h_i\n",
    "\\end{equation}\n",
    "\n",
    "and this is called the *domain* of the optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feasibility and optimality\n",
    "\n",
    "A point $x\\in \\mathcal{D}$ is *feasible* if it satisfies all the constraints, $f_i(x)\\leq 0$ and $h_i(x)=0$. The set of all feasible points is called the *feasible set*.\n",
    "\n",
    "The *optimal value* $p^*$ of the problem is defined as the set\n",
    "\n",
    "\\begin{equation}\n",
    "p^* = \\inf \\left\\{f_0(x) \\mid f_i(x) \\leq 0,\\; i=1,\\ldots,m,\\; h_i(x) = 0,\\;\n",
    "i=1,\\ldots,p\\right\\}.\n",
    "\\end{equation}\n",
    "\n",
    "**Conventions for** $p^*$\n",
    "\n",
    "- If the problem is unfeasible, we take $p^* = \\infty$. (This is because of the convention that $\\inf\\left\\{\\emptyset\\right\\} = \\infty$).\n",
    "- If there is a sequence of feasible points $x_k$ such that $f_0(x_k)\\to -\\infty$, then $p^* = -\\infty$, and we say\n",
    "the problem is *unbounded below*.\n",
    "\n",
    "Apparently, in risk-sensitive estimation, the technical name for $p^*=-\\infty$ is called *euphoric breakdown*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimal and locally optimal points**\n",
    "\n",
    "We say the point $x^*$ is an *optimal point* if $x^*$ is feasible and $f_0(x^*) = p^*$. That is, an optimal point is feasible and attains the optimal value. If an optimal point exists, we say the problem is *solvable*.\n",
    "\n",
    "There can be more than one optimal point: the set of optimal points is called the *optimal set* and is denoted \n",
    "\n",
    "\\begin{equation}\n",
    "X_{opt} = \\left\\{x \\mid f_i(x) \\leq 0,\\; i=1,\\ldots,m\\; h_i(x)=0,\\; i=1,\\ldots,p\n",
    "\\;f_0(x) = p^*\\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "A feasible point is *locally optimal* if there is an $R > 0$ such that \n",
    "\n",
    "\\begin{equation}\n",
    "f_0(x) = \\inf\\left\\{f_0(z) \\mid z \\text{ feasible},\\; \\left\\Vert z -x\\right\\Vert_{2}^{} \\leq R\\right\\}.\n",
    "\\end{equation}\n",
    "\n",
    "Loosely if $x$ is the best you can do in a ball of radius $R$, then $x$ is\n",
    "locally optimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Examples*\n",
    "\n",
    "What is the optimal set for each of the following, with $x\\in \\mathbf{R}^{}$ and $\\mathbf{dom} f = \\mathbf{R}^{}_{++}$?\n",
    "\n",
    "- For $f_0(x) = 1/x$, the optimal value $p^* = 0$, but it is never achieved.\n",
    "- For $f_0(x) = -\\log x$, $p^* = -\\infty$, and the problem is unbounded below\n",
    "- For $f_0(x) = x\\log x$, $p^* = -1/e$, which is achieved at the unique optimal point $x^*=1/e$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconstrained minimization\n",
    "\n",
    "A problem is unconstrained if it has no explicit constraints ($m=p=0$).\n",
    "\n",
    "*A simple example of an unconstrained problem with implicit constraints* \n",
    "\n",
    "consider the minimization problem\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & f_0(x) = -\\sum_{i=1}^{k} \\log\\left(b_i-a_i^T x\\right)\n",
    "\\end{align}\n",
    "\n",
    "which has implicit constraints $a_i^T x < b_i$, because $\\mathbf{dom} \\log(u) $\n",
    "is $\\mathbf{R}^{n}_{++}$. It has no constraint functions, but there are implicit\n",
    "constraints inherited from the domain of $f_0$.\n",
    "\n",
    "### Feasibility problem\n",
    "\n",
    "\\begin{align}\n",
    "\\text{find}  \\; & x      &     \\\\\n",
    "\\text{subject to}\\; & f_i(x)\\leq 0& i=1,\\ldots,m \\\\\n",
    "& h_i(x) =   0& i=1,\\ldots,p\n",
    "\\end{align}\n",
    "\n",
    "Any $x$ that satisfies the constraints is equally attractive.  The way to think about this is \n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & 0      &     \\\\\n",
    "\\text{subject to}\\; & f_i(x)\\leq 0& i=1,\\ldots,m \\\\\n",
    "& h_i(x) =   0& i=1,\\ldots,p\n",
    "\\end{align}\n",
    "\n",
    "which looks stupid, but encodes everything correctly. This way, there are two possibilities for $p^*$, either $p^* = 0$ if the contraints are feasible or $p^* = +\\infty$ if constraints are infeasible. Any feasible point is optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressing problems in standard form\n",
    "\n",
    "Equation (\\ref{eq:cvx_std_form}) describes a problem in *standard form*. Sometimes, we need to do some massaging to get a problem into standard form.\n",
    "\n",
    "### Equivalent problems\n",
    "\n",
    "Giving a rigorous definition of an equivalent problem is complicated and unnecessary. Loosely, two problems are equivalent if we can the solution for one allows us to readily find the solution to the other.\n",
    "\n",
    ">\"If you can add a small wrapper code around one problem that provides the solution to the other, the problems are equivalent.\" - Stephen Boyd\n",
    "\n",
    "This informal idea will be nonetheless completely clear when it arises. We can use change of variables, or transformation of objective and constraint functions to form equivalent problems that are easier to solve or transform a problem into standard form.\n",
    "\n",
    "#### Transformation of objective and constraint functions \n",
    "*Example: Least-norm problems*\n",
    "\n",
    "For the unconstrained Euclidean norm minimization problem\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & \\left\\Vert Ax - b\\right\\Vert_{2}\n",
    "\\label{eq:un_euc}\n",
    "\\end{align}\n",
    "\n",
    "for $x\\in \\mathbf{R}^{n}$. Since the norm is always positive, we can just as well minimize the square of the norm, solving the problem\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & \\left\\Vert Ax - b\\right\\Vert_{2}^2 = (Ax -b)^T(Ax - b)\n",
    "\\label{eq:un_euc2}\n",
    "\\end{align}\n",
    "\n",
    "These problems are equivalent: their optimal points are the same. But the problems are not the same. The objective function in equation (\\ref{eq:un_euc}) is not differentiable at any $x$ where $Ax - b = 0$, but the objective function in equation (\\ref{eq:un_euc2}) is differentiable everywhere and has a nice quadratic form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Zeroing the right-hand side\n",
    "\n",
    "If the contraint functions have nonzero righ hand-sides, just subtract.\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & f_0(x)      &     \\\\\n",
    "\\text{subject to}\\; & f_i(x)\\leq \\tilde{f}_i(x)& i=1,\\ldots,m \\\\\n",
    "& h_i(x) =  \\tilde{h}_i(x) & i=1,\\ldots,p\n",
    "\\end{align}\n",
    "gets rewritten as\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & f_0(x)      &     \\\\\n",
    "\\text{subject to}\\; & f_i(x) - \\tilde{f}_i(x) \\leq 0 & i=1,\\ldots,m \\\\\n",
    "& h_i(x) - \\tilde{h}_i(x) =0 & i=1,\\ldots,p\n",
    "\\end{align}\n",
    "\n",
    "*Example: Box constraints*\n",
    "\n",
    "For problems where each $x_i$ is subject to upper and lower bounds,\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & f_0(x)      &     \\\\\n",
    "\\text{subject to}\\; & l_i \\leq x_i\\leq u_i & i=1,\\ldots,n\n",
    "\\end{align}\n",
    "\n",
    "we split each of the constraints up, resulting in $2n$ constraints\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & f_0(x)      &     \\\\\n",
    "\\text{subject to}\\; & l_i - x_i \\leq 0 & i=1,\\ldots,n \\\\\n",
    "& x_i - u_i \\leq 0 & i=1,\\ldots,n\n",
    "\\end{align}\n",
    "\n",
    "#### Maximization problems\n",
    "\n",
    "Standard form by convention assumes a minimization problem.\n",
    "\n",
    "\\begin{align}\n",
    "\\text{maximize}  \\; & f_0(x)      &     \\\\\n",
    "\\text{subject to}\\; & f_i(x)\\leq 0& i=1,\\ldots,m \\\\\n",
    "& h_i(x) =   0& i=1,\\ldots,p\n",
    "\\end{align}\n",
    "\n",
    "So we just minimize the function $-f_0$ subject to the constraints and we're\n",
    "done.\n",
    "\n",
    "#### Eliminating inequalities with slack variables\n",
    "\n",
    "The idea behind slack variables is that we have the constraint $f_i(x) \\leq 0$ if and only if \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{there exists } s_i \\geq \\qquad \\text{such that } f_i(x) + s_i = 0.\n",
    "\\end{equation}\n",
    "\n",
    "So we can replace the standard problem with \n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & f_0(x)      &     \\\\\n",
    "\\text{subject to}\\; & s_i(x)\\geq 0& i=1,\\ldots,m \\\\\n",
    "& f_i(x) +s_i = 0  & i=1,\\ldots,m \\\\\n",
    "& h_i(x) =   0& i=1,\\ldots,p\n",
    "\\end{align}\n",
    "\n",
    "This new problem has $x\\in \\mathbf{R}^{n}$ and $s\\in \\mathbf{R}^{m}$, so there are $n+m$ variables. There are $m$ inequality constraints ensuring $s_i \\geq 0 $, and $m+p$ equality constraints.\n",
    "\n",
    "So for the price of increasing the problem size, we've replaced the inequality constraints with equality constraints and adds simple nonnegativity equality constraints.\n",
    "\n",
    "#### Eliminating linear equality constraints\n",
    "\n",
    "Notes:\n",
    "- eliminate $Ax = b$ by finding $F$ and a point $z$ such that $x = Fz + x_0$ where $x_0$ is a particular solution (can take least norm solution) of $Ax=b$. Then for any value of $z$,\n",
    "\n",
    "$$A(Fz + x_0) = b $$ for all $z$, automatically. So we don't need the constraint anymore. Then we can form the equivalent problem. The price we pay is the modest computation to calculate $F$ and $x_0$.\n",
    "\n",
    "#### Introducing equality constraints\n",
    "\n",
    "It's actually in many cases easier to solve a problem with more variables. Sounds odd, but it's true.\n",
    "\n",
    "Example:\n",
    "some math\n",
    "\n",
    "This does not look like progress, but weirdly, later we will see that this is the first step to lots of progress.\n",
    "\n",
    "#### Optimizing over some variables\n",
    "#### Epigraph problem form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex optimization\n",
    "\n",
    "Convex optimization problems have additional restrictions compared to the general optimization problem expressed in\n",
    "equation (\\ref{eq:cvx_std_form})\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & f_0(x)      &     \\\\\n",
    "\\text{subject to}\\; & f_i(x)\\leq 0& i=1,\\ldots,m \\\\\n",
    "& a_i^T x =   b_i & i=1,\\ldots,p,\n",
    "\\label{eq:cvx_problem_std}\n",
    "\\end{align}\n",
    "\n",
    "where the objective function $f_0(x)$ as well as all of the inequality\n",
    "constraint functions $f_i(x)$ are convex functions. The equality constraint\n",
    "functions must be affine.\n",
    "\n",
    "We have implicitly that the feasible set of convex optimization problem is\n",
    "convex, since it is the intersection of the domain of the problem\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{D} = \\bigcap_{i=0}^m \\mathbf{dom} f_i,\n",
    "\\end{equation}\n",
    "\n",
    "which is a convex set since it is the intersection of finitely many convex sets.\n",
    "\n",
    "### Abstract form of a convex optimization problem\n",
    "\n",
    "Some references define a convex optimization problem to be any problem in which we minimize a convex function over a convex set. However, in the Boyd book, they don't accept this; a convex problem must explicitly be expressed in terms of convex / affine constraint functions. \n",
    "\n",
    "To illustrate the distinction between the two conventions, consider the cooked-up problem in the Boyd notes\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}  \\; & x_1^2 = x_2^2     \\\\\n",
    "\\text{subject to}\\; & x_1/(1+x_2^2) \\leq 0 \\\\\n",
    "& (x_1 + x_2)^2  = 0\n",
    "\\end{align}\n",
    "\n",
    "The two constraints do describe a convex feasible set.  However, In the Boyd\n",
    "convention, this is **not** a convex problem since neither the inequality\n",
    "constraint nor the equality constraint is convex. \n",
    "\n",
    "However, the constraints are readily transformed into convex ones. We have that $x_1/(1+x_2^2)\\leq 0 \\iff x_1 \\leq 0$ and $(x_1+x_2)^2 =0 \\iff x_1 +\n",
    "x_2 = 0$, both of which are convex. So, the problem is equivalent to a convex\n",
    "problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local and global optima\n",
    "\n",
    "A fundamental property of convex optimization problems is that any locally optimal point is also globally optimal if $x$ is feasible. This relies on the convexity of the function and the domain.\n",
    "\n",
    "### Optimality criterion for differentiable $f_0$\n",
    "\n",
    "#### Unconstrained problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems with only equality constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimization over the nonnegative orthant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasiconvex optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear optimization problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value is -15.22091260446784\n",
      "A solution x is\n",
      "[-1.10131657 -0.16370661 -0.89711643  0.03228612  0.60662428 -1.12655967\n",
      "  1.12985839  0.88200333  0.49089264  0.89851057]\n",
      "A dual solution is\n",
      "[0.         0.61175641 0.52817175 1.07296862 0.         2.3015387\n",
      " 0.         0.7612069  0.         0.24937038 0.         2.06014071\n",
      " 0.3224172  0.38405435 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Import packages.\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Generate a random non-trivial linear program.\n",
    "m = 15\n",
    "n = 10\n",
    "np.random.seed(1)\n",
    "s0 = np.random.randn(m)\n",
    "lamb0 = np.maximum(-s0, 0)\n",
    "s0 = np.maximum(s0, 0)\n",
    "x0 = np.random.randn(n)\n",
    "A = np.random.randn(m, n)\n",
    "b = A@x0 + s0\n",
    "c = -A.T@lamb0\n",
    "\n",
    "# Define and solve the CVXPY problem.\n",
    "x = cp.Variable(n)\n",
    "prob = cp.Problem(cp.Minimize(c.T@x),\n",
    "                 [A@x <= b])\n",
    "prob.solve()\n",
    "\n",
    "# Print result.\n",
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "print(\"A solution x is\")\n",
    "print(x.value)\n",
    "print(\"A dual solution is\")\n",
    "print(prob.constraints[0].dual_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic optimization problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized inequality constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:NMSMExp_env]",
   "language": "python",
   "name": "conda-env-NMSMExp_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
